\subsection{The Virtual Soundstage}

The abstracted virtual space will be a two-dimensional space with orthogonal basis $(\hat{x},\hat{y})$. For ease of visualization, $\hat{x}$ will be considered as left-pointing, and $\hat{y}$ will be considered as pointing forward and bisecting the soundstage. Thus, the used virtual soundstage area will be the area within the range of positive $y$; the positive $x$ direction will be perceptual left, and the negative $x$ direction will be perceptual right.

\subsection{The Sound Source}

\subsubsection{The propagation of sound from real sound sources}

The first immediate barrier to modeling the propagation of sound from a sound source is the nature of any given sound source. Few acoustic resonators approach being perfect point sources with equal spherical radiation of sound across the entire audible frequency spectrum. It is, in theory, possible to model the emission of sound using frequency-dependent statistical directivity data derived from various instruments. This model could be applied to the algorithm if the facing of the sound source was known. However, chasing down this trail raises questions into the propagation of sound towards any given microphone, the effect of the physical characteristics of the sound stage, and the effect of height components in the positioning of the source and microphones. 

Trying to account for all of these components would eventually necessitate venturing into the realm of physical modeling. While such an undertaking is a worthwhile avenue of research, it breaks this processor's goals of ease of use and intuition of abstraction, as well violating the goal of remaining computationally efficient enough to use as a general DAW plug-in. 

A review of literature regarding stereophonic recording practice tends to focus on the directional characteristics of sound sources as considerations for the height of microphones in the array, with the aim of obtaining the desired blend of each sourceâ€™s characteristic frequency components, as well as informing the optimal placement of spot/area microphones. The effect that a sound source's directivity can have on localization does not seem to be a remarkable characteristic of stereophonic recording arrays.

\subsubsection{The virtual sound source}

Based on the typical assumptions of stereophonic recording praxis, the virtual sound source can be considered as an ideal sound radiator which radiates sound equally towards every measured virtual point. The virtual sound source, $S$, has its location at $(r, \theta)$ and does not have any other properties -- it does not inherently apply any frequency/amplitude transfer function onto the pre-encoded signal.

The useable range of $\theta_S$, in keeping with the bounds of the defined virtual soundstage is $[0, \pi]$. The radial distance $r_S$ is an abstraction of a real distance in meters. 

Since the virtual sound source only imparts positional data to the sound, the actual recorded sound to be encoded can also be represented by $S$; where $S$ is the recorded sound, which is emitted into the virtual space at point $(r, \theta)$\footnote{The choice of polar coordinates to represent the position of $S$ is semi-arbitrary, and does owe some part to the specifics of the implementation. An origin shift will be necessary during the processing which will require the translation of the polar coordinates into cartesian, however there will be a second translation back to polar coordinates again. In this sense, the source is always conceptually considered based on its angle and distance from some reference point. Thus, it seems natural to define $S$ in those terms.}

\subsection{Virtual Microphones}

The virtual stereophonic array can be represented as a set of virtual microphones, $M \: | \: M = \{m_1, ... m_n\}$. Each virtual microphone has its placement within the virtual space at coordinates $(x,y)$, and has orientation $\theta$, with polar directivity factor $p$.

The orientation, $\theta$ of the virtual microphone represents is direction of facing into the soundstage. Like $\theta_s$, the range of usable values is $[0, \pi]$ where a rotation of $0$ indicates a facing directly to the left, a facing of $\pi$ is directly to the right, and an orientation of $\frac{\pi}{2}$ points the virtual microphone directly forward -- parallel to the $y$-axis with a lateral offset of $x_m$.

The polar directivity value, $p$ is a real number in the range $[0,1]$ where $p=0$ yields a non-directional polar directivity pattern, and $p=1$ yields a bidirectional polar directivity pattern. The resulting polar attenuation pattern at angle of arrival (relative to the ``font'' of the virtual microphone) $\phi$ for any value of $p$ can be found as:

\begin{equation}\label{polarPatternPlot}
m(p,\phi) = (1-p) + p\cos(\phi)
\end{equation}

\subsubsection{Limitations in abstracting ideal microphones}

It should be noted that real microphones' polar patterns are frequency-dependent, with cardioid microphones ($0 < p < 1$) becoming increasingly less directional at lower frequencies. At higher frequencies, the physical body of the microphone and the diameter of the microphone diaphragm also begin to affect in the polar response. Additionally, cardioid microphones -- due to the physical mechanics of generating a cardioid polar pattern -- tend to exhibit a marked attenuation in their frequency response at lower frequencies.

Often, the specific color that a specific model of microphone imparts on the recorded sound is carefully chosen, with the choice of microphone being considered one of the major creative decisions in recording and the design of many microphones being intentional to support specific colorations and yield various creative options. It would be impractical to try and model the specific responses of common microphones used in main arrays, and the processing needed to apply the frequency-domain modeling would break the CPU-efficiency goal. Additionally, an attempt to reproduce the frequency-domain aspects of a stereophonic array would have the effect of distorting the (likely intentionally-chosen) frequency-domain aspects of the source recording.

Thus, using virtual microphones with ideal polar patterns is likely the optimal use-case for most users. This will be with the understanding that the virtual microphone array will impart localization cues that approach that of a real microphone array, but -- due to limitations in modeling real-world physics -- will not fully replicate the cues of a real-world microphone array. However, the processor will provide localization cues that are closer than level-difference-only panning methodologies.

There is one case that is worth considering. As previously noted, directional microphones tend to exhibit a marked attenuation at low-frequencies. There are some recording techniques that take advantage of this tendency, especially since the human prioritization of localization cues is frequency-dependent. It may be desirable to include some simple high-pass and low-pass filter options within the implementation to allow the user to emulate some of the key frequency-dependent behavior.

\subsection{The User Interface}

In the implementation of the processor, the relevant controls for defining the desired virtual objects and their parameters need to be exposed to the user. For the virtual sound source, this means exposing controls for $\theta_S$ and $r_S$. Then the number of virtual microphones in set $M$ needs to be defined, the relevant values for $p_m$, $(x_m,y_m)$, and $\theta_m$ need to be exposed.

\subsubsection{Orienting the user within the virtual space} The first concern is presenting the orientation of the virtual space to the user in a way allows them to be intuitively oriented within and able to intuitively understand the distances and placements of virtual objects with in. Thus, establishing an intuitive reference for the placement of the origin of the space is of primary importance.

Following the specific facings of the basis $(\hat{x},\hat{y})$, the most logical place to orient $O$ would be at the central point of the microphone array -- which is also what user will intuit as the "perceptual center". This also gives a consistent and predictable basis for user to take real-world measurements and translate them into the virtual abstraction used by the processor.

\subsubsection{Orienting the virtual sound source} The typical mixing engineer is likely to naturally think of angular rotation in terms of radians. Similarly, considering the amount of angular rotation from the $x$-axis is not reflective of the "front" oriented human experience. Thus, the user interface is better presented with $\theta_S$ translated as degrees of deflection from forward. Additionally, there is a bias (at least within Western culture) that a numerical increase in amount be translated as right-ward motion. Due to this, the number of degrees needs to decrease with counter-clockwise rotation.

Thus, if $\phi$ is the value, in degrees of deflection from forward, then:

\begin{equation}
\theta_S = (-\phi + 90) * \frac{\pi}{180} \; | \; \phi = [-90,90]
\end{equation}

Since $r$ is abstracted as meters, the user can specify the distance $r$ from point $O$ directly -- understanding it as the distance from the center of the real (or imagined) microphone array.

\subsubsection{Constructing the microphone array}

The set of microphones in the virtual array, $M$, is some number of virtual microphones. While it is possible to define an arbitrary number of virtual microphones each at any conceivable position within the virtual space and define the algorithm in a way to accommodate, usual stereophonic recording practice, again, gives some practical limits that can be used to refine and focus the amount of controls exposed to the user and enhance the quality of the user experience.

The fundamental praxis of stereophonic recording is based on the use of a microphone pair, that translate to the raw left and right audio channels. This microphone pair is laterally spaced at some distance, and has an angular splay of some angle. This primary pair can be designated the ``main' stereo pair, $m_\text{mains}$, that has the properties of its lateral distance, $d$, angular splay, $\phi$.

As discussed in the overview, it is also common to use a second pair of microphones in tandem to the first, that occupy a wider spacing. These additional microphones can be designated as the "flanks", $m_\text{flanks}$. The flank pair will have the same properties, $d$ and $\phi$, as the main pair.

Finally, there is a long tradition of using a center microphone, $m_\text{center}$. Typically, the center microphone does not rotate in the 2D plane; so, it will only have a distance, $d$. However, for a center microphone, the displacement is forward, rather than lateral; following this, any value for $d_\text{center}$ will be long the $y$ axis.

This gives a maximum size of $M$ of $n=5$, which is a manageable number. These are presented to the user as two pairs and the single center microphone. The preferred ordering of the microphones within $M$ will follow the order of expected frequency of use (mains, flanks, center), and the audio-industry preference for left-right ordering of channels:

\begin{equation}
M = \{m_\text{mL}, m_\text{mR}, m_\text{fL}, m_\text{fR}, m_\text{c}\}
\end{equation}

The two pairs and center microphone are each switchable, so that the user can freely enable/disable any combination of them. Each microphone group also has a control exposed that applies an amplitude scalar to the signal of that group, to allow for different proportions of that group's signal into the output\footnote{Ideally, the plug-in would be able to output the individual processing of each microphone; however the format of the competition that the plug-in was designed for limits the output channels to two.}. This scalar, $g$, has an adjustment range in decibels: $g = [-20,0]$.

\subsubsection{Identifying virtual microphone distance limits}

Identifying practical limits for the $d$ value for the two pairs will require a bit of arbitrary demarcation. The main pair must allow for a minimum of $d_\text{mains}=0$ to accommodate coincident microphone techniques. Likewise, for flexibility and simplicity there is little reason not to allow $d_\text{flanks} = 0$ (though it would an odd use-case for this value to be used). For the center microphone, while it is common in many cases for it to be displaced forward, there are also a number of cases that require it to remain in-line with adjacent pairs; so a minimum value of $d_\text{center} = 0$ is also necessary to accommodate all reasonable use-cases.

For maximal allowed values, and examination of the literature shows that main mic pairs usually occur in spaces smaller than 100cm, however triplets can employ rather wide distances, with ``typical'' Decca-tree configurations spanning 2m. The current implementation allows for a maximal span of 3m to accommodate some extra working room for three-microphone expanded configurations, additionally, due to the common use of $d < 1m$, the values for $d_\text{mains}$ are presented to the user in centimeters; this gives $0 \leq d_\text{mains} \leq 300$ as the total range for the mains' lateral distance.

After an informal poll and discussion with several sound recordists who specialize in acoustic ensemble recording, an upper limit of 10m was chosen for the flanking pair. This gives $0 \leq d_\text{flanks} \leq 10$ as the total range for the flanks' lateral distance, and this presented to the user in meters.

Finally, the maximum amount of forward displacement for the center microphone is was set to $d_\text{center} = 100$ in centimeters. Common uses of a forward-set center microphone are under this threshold, and the 100cm point allows for a round number as the limit and offers some extra distance as a buffer to catch reasonable outliers.

\subsubsection{Microphone UI parameter conversion to values for calculation}

A key aspect of many stereophonic recording arrays is bilateral symmetry. Hence the focus on pairs of microphones and defining them in terms of their mutual distance and angular splay. Because of this, it can be assumed that for any of the paired microphones:

\begin{equation}
d_{\vec{mO}} = \frac{d_m}{2}
\end{equation}

Since the standard abstracted unit of measure in the virtual space is a meter, the distances for the center microphone and the main pair will need to be converted from the centimeter presentation to the user. Since every microphone only moves along one axis, and does not cross the origin, its position along the other axis will remain fixed at $0$. For the pairs of microphones, the symmetry at the $y$-axis means that the left microphone of each pair will remain in the span $d_L \leq 0$ whereas the right microphone in each pair will be within the span $d_R \geq 0$.

Thus, for the pairs of microphones:

\begin{equation}
\begin{bmatrix} x_L \\ x_R \end{bmatrix} = C0.5 \begin{bmatrix} -d_m \\ +d_m \end{bmatrix}
\end{equation}

Where $C$ is the unit conversion constant: $C_\text{mains} = 0.01$ and $C_\text{flanks} = 1$.

The value of $d_c$ can be directly converted into meters, and used as the $y$-coordinate value for the center microphone:

\begin{equation}
x_c = 0.01d_m
\end{equation}

For the angular splay values of the microphone pairs a similar conversion can be used. Since the angular splay value is the angle between the microphones, the deflection from forward can be found by halving the angular splay. Since perceptual forward is at an angular rotation of $\frac{\pi}{2}$, the left and right microphones' rotation values can be found by adding or subtracting the deflection value (converted to radians) from $\frac{\pi}{2}$:

\begin{equation}
\begin{bmatrix} \theta_L \\ \theta_R \end{bmatrix} = \frac{\phi\pi}{360}J_{2,1} + \begin{bmatrix} +\frac{\pi}{2} \\ -\frac{\pi}{2} \end{bmatrix}
\end{equation}

Where $\phi$ is the angular splay value in degrees and $J$ is a matrix of ones.
